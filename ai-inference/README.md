# RingRift AI Inference Service

Minimal AI service for production game server. Serves AI moves without any training infrastructure.

## Purpose

This service is the **production deployment** of RingRift AI. It:

- Serves AI moves via HTTP API
- Loads pre-trained models at startup
- Has minimal dependencies (no training, no daemons, no P2P)

For **training new models**, see `ai-service/` which contains the full training infrastructure.

## Architecture

```
ai-inference/           ← This service (production)
├── inference/main.py   ← FastAPI server (~150 lines)
├── models/             ← Pre-trained .pth files
└── Dockerfile

ai-service/             ← Training infrastructure (development)
├── app/coordination/   ← 132 daemons (NOT needed for production)
├── scripts/p2p/        ← Distributed training (NOT needed for production)
└── ...
```

## Quick Start

### Local Development

```bash
# From repo root
cd ai-inference

# Install dependencies (uses ai-service venv for shared deps)
# Or: pip install -r requirements.txt

# Copy models from ai-service
cp ../ai-service/models/canonical_*.pth models/

# Run server (from repo root)
PYTHONPATH="ai-service:ai-inference" python -m uvicorn inference.main:app --port 8001
```

### Docker

```bash
# Build (from repo root)
docker build -f ai-inference/Dockerfile -t ringrift-ai-inference .

# Run
docker run -p 8001:8001 ringrift-ai-inference
```

### Docker Compose (with game server)

```bash
docker compose -f docker-compose.production.yml up
```

## API

### GET /health

Health check endpoint.

```bash
curl http://localhost:8001/health
```

Response:

```json
{
  "status": "ok",
  "models_loaded": 6,
  "model_keys": ["hex8_2p", "hex8_3p", "hex8_4p", "square8_2p", "square8_3p", "square8_4p"]
}
```

### POST /move

Get AI move for a game state.

```bash
curl -X POST http://localhost:8001/move \
  -H "Content-Type: application/json" \
  -d '{
    "game_state": {...},
    "player_number": 1,
    "difficulty": 3
  }'
```

Response:

```json
{
  "move": {"type": "place_ring", "to": {"x": 3, "y": 4}, ...},
  "evaluation": 0.65,
  "thinking_time_ms": 42,
  "difficulty": 3,
  "ai_type": "minimax"
}
```

### Difficulty Levels

| Level | AI Type        | Description            |
| ----- | -------------- | ---------------------- |
| 1     | Random         | Random valid moves     |
| 2     | Heuristic      | Basic strategy         |
| 3     | Minimax + NNUE | Intermediate (default) |
| 4     | MCTS           | Advanced search        |
| 5     | Gumbel MCTS    | Expert level           |

## Environment Variables

| Variable               | Default    | Description         |
| ---------------------- | ---------- | ------------------- |
| `PORT`                 | 8001       | Server port         |
| `RINGRIFT_MODELS_PATH` | `./models` | Path to model files |
| `RINGRIFT_LOG_LEVEL`   | INFO       | Logging level       |

## Model Files

The service expects pre-trained models in the `models/` directory:

```
models/
├── canonical_hex8_2p.pth
├── canonical_hex8_3p.pth
├── canonical_hex8_4p.pth
├── canonical_square8_2p.pth
├── canonical_square8_3p.pth
└── canonical_square8_4p.pth
```

Models are generated by the `ai-service/` training pipeline and should be copied here for production deployment.

## Comparison: ai-inference vs ai-service

| Aspect        | ai-inference              | ai-service                   |
| ------------- | ------------------------- | ---------------------------- |
| Purpose       | Serve moves in production | Train models                 |
| Lines of code | ~150                      | ~235,000                     |
| Daemons       | 0                         | 132                          |
| Dependencies  | torch, fastapi            | torch, fastapi + 50 packages |
| Endpoints     | 2 (/health, /move)        | 20+                          |
| Startup time  | <5 seconds                | 30+ seconds                  |
| Memory        | ~500MB                    | 2-8GB                        |

## Integration with Game Server

The Node.js game server calls this service for AI moves:

```typescript
// In game server
const response = await fetch('http://ai-inference:8001/move', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    game_state: gameState,
    player_number: currentPlayer,
    difficulty: aiDifficulty,
  }),
});

const { move } = await response.json();
```

## Deployment

### Production Checklist

- [ ] Copy canonical models to `models/`
- [ ] Set appropriate `RINGRIFT_MODELS_PATH`
- [ ] Configure health checks in orchestrator
- [ ] Set resource limits (CPU: 1, Memory: 1GB minimum)
- [ ] Enable GPU if available for faster inference

### Scaling

For high traffic:

- Run multiple instances behind a load balancer
- Models are read-only, so instances share nothing
- Consider GPU instances for difficulty 4-5 (MCTS/Gumbel)
